# LLMFlow 프로토콜정의서

## 문서 정보

| 항목 | 내용 |
|------|------|
| 문서명 | LLMFlow 프로토콜정의서 |
| 버전 | 2.0 (오픈소스 조합 가이드 반영) |
| 작성일 | 2025-12-13 |

---

## 1. 통신 프로토콜 개요

### 1.1 프로토콜 매트릭스

| 소스 | 대상 | 프로토콜 | 포트 | 암호화 | 인증 |
|------|------|----------|------|--------|------|
| Client | APISIX | HTTPS | 443 | TLS 1.3 | JWT/API Key |
| Client | APISIX | WSS | 443 | TLS 1.3 | JWT |
| APISIX | Keycloak | HTTPS | 8443 | TLS 1.3 | OIDC |
| APISIX | Dify API | HTTP | 8080 | mTLS | Internal |
| Dify | PostgreSQL | PostgreSQL | 5432 | TLS | Password |
| Dify | Redis | Redis | 6379 | TLS | Password |
| Dify | Milvus | gRPC | 19530 | TLS | Token |
| Dify | Neo4j | Bolt | 7687 | TLS | Password |
| Dify | vLLM | HTTP | 8000 | mTLS | API Key |
| Dify | TEI/Infinity | HTTP | 8080 | mTLS | Internal |
| Dify | Unstructured | HTTP | 8000 | mTLS | API Key |
| Dify | MinIO | HTTP | 9000 | TLS | Access Key |
| Dify | Langfuse | HTTPS | 3000 | TLS | API Key |
| LlamaIndex | Neo4j | Bolt | 7687 | TLS | Password |
| Prometheus | All | HTTP | 9090 | Internal | - |

### 1.2 TLS 구성

```yaml
# TLS 설정 표준
tls:
  version: "1.3"
  ciphers:
    - TLS_AES_256_GCM_SHA384
    - TLS_CHACHA20_POLY1305_SHA256
  certificate:
    validity: 365d
    key_size: 4096
    algorithm: RSA
  mtls:
    enabled: true
    verify_client: true
```

---

## 2. API 명세

### 2.1 LLM 추론 API (OpenAI 호환 - vLLM)

#### Chat Completions

**엔드포인트**: `POST /v1/chat/completions`

**요청 헤더**:
```http
Authorization: Bearer <api_key>
Content-Type: application/json
X-Request-ID: <uuid>
X-Tenant-ID: <tenant_id>
```

**요청 본문**:
```json
{
  "model": "llama-3.1-70b",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "안녕하세요, 회사 정책에 대해 알려주세요."
    }
  ],
  "temperature": 0.7,
  "max_tokens": 2048,
  "top_p": 0.9,
  "stream": true,
  "stop": ["\n\n"],
  "user": "user_123"
}
```

**응답 (스트리밍)**:
```
data: {"id":"chatcmpl-xxx","object":"chat.completion.chunk","created":1702000000,"model":"llama-3.1-70b","choices":[{"index":0,"delta":{"role":"assistant","content":"안녕"},"finish_reason":null}]}

data: {"id":"chatcmpl-xxx","object":"chat.completion.chunk","created":1702000000,"model":"llama-3.1-70b","choices":[{"index":0,"delta":{"content":"하세요"},"finish_reason":null}]}

data: {"id":"chatcmpl-xxx","object":"chat.completion.chunk","created":1702000000,"model":"llama-3.1-70b","choices":[{"index":0,"delta":{},"finish_reason":"stop"}],"usage":{"prompt_tokens":50,"completion_tokens":100,"total_tokens":150}}

data: [DONE]
```

**응답 (비스트리밍)**:
```json
{
  "id": "chatcmpl-xxx",
  "object": "chat.completion",
  "created": 1702000000,
  "model": "llama-3.1-70b",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "안녕하세요! 회사 정책에 대해 도움을 드리겠습니다..."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 50,
    "completion_tokens": 100,
    "total_tokens": 150
  }
}
```

#### Models

**엔드포인트**: `GET /v1/models`

**응답**:
```json
{
  "object": "list",
  "data": [
    {
      "id": "llama-3.1-70b",
      "object": "model",
      "created": 1702000000,
      "owned_by": "llmflow",
      "permission": [],
      "root": "llama-3.1-70b",
      "parent": null
    },
    {
      "id": "mistral-7b",
      "object": "model",
      "created": 1702000000,
      "owned_by": "llmflow"
    }
  ]
}
```

### 2.2 TEI / Infinity API (임베딩 & 리랭킹)

#### Embedding API

**엔드포인트**: `POST /embed`

**요청**:
```json
{
  "inputs": ["검색할 텍스트", "다른 텍스트"],
  "normalize": true,
  "truncate": true
}
```

**응답**:
```json
[
  [0.0023064255, -0.009327292, 0.012345678, ...],
  [-0.0028842222, 0.0073518134, 0.009876543, ...]
]
```

#### OpenAI 호환 Embedding API (선택적)

**엔드포인트**: `POST /v1/embeddings`

**요청**:
```json
{
  "model": "bge-m3",
  "input": ["검색할 텍스트", "다른 텍스트"],
  "encoding_format": "float"
}
```

**응답**:
```json
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "index": 0,
      "embedding": [0.0023064255, -0.009327292, ...]
    },
    {
      "object": "embedding",
      "index": 1,
      "embedding": [-0.0028842222, 0.0073518134, ...]
    }
  ],
  "model": "bge-m3",
  "usage": {
    "prompt_tokens": 15,
    "total_tokens": 15
  }
}
```

#### Reranking API

**엔드포인트**: `POST /rerank`

**요청**:
```json
{
  "query": "연차 휴가 신청 방법",
  "texts": [
    "연차 휴가는 그룹웨어에서 신청합니다.",
    "회사 정책은 매년 업데이트됩니다.",
    "휴가 신청은 최소 3일 전에 해야 합니다."
  ],
  "return_text": false,
  "truncate": true
}
```

**응답**:
```json
[
  {"index": 0, "score": 0.95},
  {"index": 2, "score": 0.78},
  {"index": 1, "score": 0.12}
]
```

### 2.3 Unstructured API (ETL/문서 파싱)

#### 문서 파싱

**엔드포인트**: `POST /general/v0/general`

**요청**:
```http
Content-Type: multipart/form-data

files: <binary file>
strategy: "hi_res"
hi_res_model_name: "yolox"
pdf_infer_table_structure: true
skip_infer_table_types: []
```

**응답**:
```json
[
  {
    "type": "Title",
    "element_id": "abc123",
    "text": "회사 연차 휴가 규정",
    "metadata": {
      "filename": "vacation_policy.pdf",
      "page_number": 1,
      "coordinates": {
        "points": [[72, 100], [540, 100], [540, 120], [72, 120]],
        "system": "PixelSpace"
      }
    }
  },
  {
    "type": "NarrativeText",
    "element_id": "def456",
    "text": "본 규정은 모든 정규직 직원에게 적용됩니다...",
    "metadata": {
      "filename": "vacation_policy.pdf",
      "page_number": 1
    }
  },
  {
    "type": "Table",
    "element_id": "ghi789",
    "text": "| 근속연수 | 연차일수 |\n|---------|--------|\n| 1년 미만 | 11일 |\n| 1년 이상 | 15일 |",
    "metadata": {
      "filename": "vacation_policy.pdf",
      "page_number": 2,
      "text_as_html": "<table>...</table>"
    }
  }
]
```

#### 지원 Element 타입

| 타입 | 설명 |
|------|------|
| `Title` | 제목, 헤더 |
| `NarrativeText` | 본문 텍스트 |
| `Table` | 표 |
| `ListItem` | 목록 항목 |
| `Image` | 이미지 (OCR 결과 포함) |
| `FigureCaption` | 그림 캡션 |
| `Header` | 페이지 헤더 |
| `Footer` | 페이지 푸터 |
| `PageBreak` | 페이지 구분 |

### 2.4 Neo4j API (GraphRAG)

#### Cypher 쿼리 실행

**프로토콜**: Bolt (bolt://)

**연결 URL**: `bolt://neo4j:7687`

**GraphRAG 엔티티 검색 쿼리**:
```cypher
// 관련 엔티티 및 관계 검색
MATCH (c:Chunk)-[:MENTIONS]->(e:Entity)
WHERE c.embedding_id IN $chunk_ids
WITH e, count(c) as mention_count
ORDER BY mention_count DESC
LIMIT 10

MATCH (e)-[r:RELATED_TO]-(related:Entity)
RETURN e, collect({
  entity: related,
  relation: type(r),
  properties: properties(r)
}) as relations
```

**지식 그래프 확장 쿼리**:
```cypher
// 2-hop 관계 탐색
MATCH path = (start:Entity {name: $entity_name})-[*1..2]-(end:Entity)
WHERE ALL(r IN relationships(path) WHERE r.weight > 0.5)
RETURN path
LIMIT 50
```

**HTTP API (선택적)**:

**엔드포인트**: `POST /db/{database}/tx/commit`

**요청**:
```json
{
  "statements": [
    {
      "statement": "MATCH (n:Entity) WHERE n.name = $name RETURN n",
      "parameters": {
        "name": "연차휴가"
      }
    }
  ]
}
```

### 2.5 RAG API

#### 문서 업로드

**엔드포인트**: `POST /api/v1/datasets/{dataset_id}/documents`

**요청**:
```http
Content-Type: multipart/form-data

file: <binary>
metadata: {
  "title": "회사 정책 문서",
  "department": "HR",
  "tags": ["정책", "규정"]
}
processing_config: {
  "parser": "unstructured",
  "chunking_strategy": "semantic",
  "chunk_size": 512,
  "chunk_overlap": 50,
  "enable_graph_extraction": true
}
```

**응답**:
```json
{
  "id": "doc_xxx",
  "dataset_id": "ds_xxx",
  "name": "회사정책.pdf",
  "status": "processing",
  "created_at": "2025-12-13T10:00:00Z",
  "metadata": {
    "title": "회사 정책 문서",
    "department": "HR",
    "tags": ["정책", "규정"]
  },
  "processing": {
    "total_chunks": null,
    "processed_chunks": 0,
    "status": "parsing",
    "stages": ["parsing", "chunking", "embedding", "graph_extraction", "indexing"]
  }
}
```

#### RAG 검색 (하이브리드)

**엔드포인트**: `POST /api/v1/datasets/{dataset_id}/search`

**요청**:
```json
{
  "query": "연차 휴가 신청 방법",
  "top_k": 10,
  "score_threshold": 0.7,
  "filter": {
    "department": ["HR", "SHARED"]
  },
  "search_mode": "hybrid",
  "hybrid_config": {
    "vector_weight": 0.7,
    "graph_weight": 0.3,
    "enable_reranking": true,
    "rerank_top_k": 5
  },
  "include_metadata": true,
  "include_graph_context": true
}
```

**응답**:
```json
{
  "results": [
    {
      "id": "chunk_xxx",
      "document_id": "doc_xxx",
      "content": "연차 휴가 신청은 그룹웨어 시스템에서...",
      "score": 0.92,
      "rerank_score": 0.95,
      "metadata": {
        "document_name": "연차관리규정.pdf",
        "page": 3,
        "department": "HR"
      },
      "graph_context": {
        "entities": [
          {"name": "연차휴가", "type": "Policy"},
          {"name": "그룹웨어", "type": "System"}
        ],
        "relations": [
          {"source": "연차휴가", "relation": "MANAGED_BY", "target": "그룹웨어"}
        ]
      }
    }
  ],
  "timing": {
    "embedding_ms": 45,
    "vector_search_ms": 12,
    "graph_search_ms": 25,
    "rerank_ms": 30,
    "total_ms": 112
  }
}
```

### 2.6 워크플로우 API

#### 워크플로우 실행

**엔드포인트**: `POST /api/v1/workflows/{workflow_id}/run`

**요청**:
```json
{
  "inputs": {
    "query": "2024년 매출 현황 분석해줘",
    "context": {
      "user_department": "Finance",
      "access_level": "manager"
    }
  },
  "response_mode": "streaming",
  "user": "user_123"
}
```

**응답 (스트리밍)**:
```
event: workflow_started
data: {"workflow_run_id": "run_xxx", "status": "running"}

event: node_started
data: {"node_id": "node_1", "node_type": "llm", "title": "분석 요청"}

event: text_chunk
data: {"text": "2024년 매출 분석 결과입니다..."}

event: node_finished
data: {"node_id": "node_1", "outputs": {...}, "elapsed_time": 2.5}

event: workflow_finished
data: {"workflow_run_id": "run_xxx", "status": "succeeded", "outputs": {...}, "total_tokens": 500}
```

### 2.7 관리 API

#### 사용자 관리

**엔드포인트**: `POST /api/v1/admin/users`

**요청**:
```json
{
  "email": "user@company.com",
  "name": "홍길동",
  "department": "IT",
  "role": "member",
  "quota": {
    "tokens_per_month": 1000000,
    "requests_per_minute": 60
  }
}
```

#### 사용량 조회

**엔드포인트**: `GET /api/v1/admin/usage`

**쿼리 파라미터**:
```
start_date=2025-12-01
end_date=2025-12-13
group_by=department
```

**응답**:
```json
{
  "usage": [
    {
      "department": "IT",
      "total_tokens": 5000000,
      "total_requests": 10000,
      "models": {
        "llama-3.1-70b": {
          "tokens": 3000000,
          "requests": 5000
        },
        "mistral-7b": {
          "tokens": 2000000,
          "requests": 5000
        }
      },
      "embedding_requests": 15000,
      "rerank_requests": 8000
    }
  ],
  "period": {
    "start": "2025-12-01T00:00:00Z",
    "end": "2025-12-13T23:59:59Z"
  }
}
```

---

## 3. 이벤트/메시지 프로토콜

### 3.1 WebSocket 프로토콜

#### 연결

```
wss://llmflow.company.com/ws/chat
```

**연결 헤더**:
```http
Authorization: Bearer <jwt_token>
Sec-WebSocket-Protocol: llmflow-v1
```

#### 메시지 형식

**클라이언트 → 서버**:
```json
{
  "type": "chat.message",
  "id": "msg_xxx",
  "conversation_id": "conv_xxx",
  "content": "안녕하세요",
  "timestamp": "2025-12-13T10:00:00Z"
}
```

**서버 → 클라이언트**:
```json
{
  "type": "chat.response",
  "id": "resp_xxx",
  "conversation_id": "conv_xxx",
  "content": "안녕하세요! 무엇을 도와드릴까요?",
  "is_final": false,
  "timestamp": "2025-12-13T10:00:01Z"
}
```

#### 이벤트 타입

| 타입 | 방향 | 설명 |
|------|------|------|
| `chat.message` | C→S | 사용자 메시지 |
| `chat.response` | S→C | AI 응답 (스트리밍) |
| `chat.response.end` | S→C | AI 응답 완료 |
| `typing.start` | S→C | 입력 중 표시 |
| `typing.stop` | S→C | 입력 중 해제 |
| `error` | S→C | 에러 발생 |
| `ping` | 양방향 | 연결 유지 |
| `pong` | 양방향 | ping 응답 |

### 3.2 비동기 작업 이벤트

#### Redis Pub/Sub 채널

| 채널 | 용도 |
|------|------|
| `llmflow:jobs:status` | 작업 상태 변경 |
| `llmflow:documents:indexed` | 문서 인덱싱 완료 |
| `llmflow:documents:parsed` | 문서 파싱 완료 (Unstructured) |
| `llmflow:graph:extracted` | 그래프 추출 완료 (Neo4j) |
| `llmflow:models:deployed` | 모델 배포 완료 |
| `llmflow:alerts` | 시스템 알림 |

#### 이벤트 형식

```json
{
  "event_id": "evt_xxx",
  "event_type": "document.indexed",
  "timestamp": "2025-12-13T10:00:00Z",
  "payload": {
    "document_id": "doc_xxx",
    "dataset_id": "ds_xxx",
    "chunks_count": 150,
    "entities_count": 45,
    "relations_count": 78,
    "status": "completed"
  },
  "metadata": {
    "tenant_id": "tenant_xxx",
    "user_id": "user_xxx"
  }
}
```

---

## 4. 내부 통신 프로토콜

### 4.1 Dify-vLLM 통신

**프로토콜**: HTTP/2 (OpenAI 호환)

**요청 형식**:
```http
POST /v1/chat/completions HTTP/2
Host: vllm-service.llmflow-inference:8000
Content-Type: application/json
X-Internal-Request: true
X-Trace-ID: trace_xxx
```

### 4.2 Dify-TEI/Infinity 통신

**프로토콜**: HTTP/1.1

**Embedding 요청**:
```http
POST /embed HTTP/1.1
Host: tei-embedding.llmflow-inference:80
Content-Type: application/json
X-Internal-Request: true

{
  "inputs": ["텍스트1", "텍스트2"]
}
```

**Reranking 요청**:
```http
POST /rerank HTTP/1.1
Host: tei-reranker.llmflow-inference:80
Content-Type: application/json
X-Internal-Request: true

{
  "query": "검색 질의",
  "texts": ["후보1", "후보2", "후보3"]
}
```

### 4.3 Dify-Milvus 통신

**프로토콜**: gRPC

**서비스 정의**:
```protobuf
service MilvusService {
  rpc CreateCollection(CreateCollectionRequest) returns (Status);
  rpc Insert(InsertRequest) returns (MutationResult);
  rpc Search(SearchRequest) returns (SearchResults);
  rpc Query(QueryRequest) returns (QueryResults);
  rpc Delete(DeleteRequest) returns (MutationResult);
}

message SearchRequest {
  string collection_name = 1;
  repeated string partition_names = 2;
  string dsl = 3;
  repeated bytes placeholder_group = 4;
  int64 travel_timestamp = 5;
  int64 guarantee_timestamp = 6;
}
```

### 4.4 LlamaIndex-Neo4j 통신

**프로토콜**: Bolt (neo4j://)

**연결 설정**:
```python
from neo4j import GraphDatabase

driver = GraphDatabase.driver(
    "bolt://neo4j.llmflow-data:7687",
    auth=("neo4j", "${NEO4J_PASSWORD}"),
    encrypted=True,
    trust=TRUST_SYSTEM_CA_SIGNED_CERTIFICATES
)
```

**GraphRAG 인덱싱 트랜잭션**:
```cypher
// 청크와 엔티티 관계 생성
UNWIND $entities as entity
MERGE (e:Entity {name: entity.name})
SET e.type = entity.type, e.description = entity.description

WITH e
MATCH (c:Chunk {id: $chunk_id})
MERGE (c)-[:MENTIONS {confidence: $confidence}]->(e)
```

### 4.5 Unstructured-LlamaIndex 통신

**프로토콜**: HTTP

**파이프라인 흐름**:
```
[문서 업로드]
     │
     ▼
[Unstructured API 호출]
POST /general/v0/general
     │
     ▼
[파싱 결과 (Elements)]
     │
     ▼
[LlamaIndex 변환]
UnstructuredElementNodeParser
     │
     ▼
[청킹 + 임베딩]
TEI /embed
     │
     ▼
[인덱싱]
Milvus + Neo4j
```

---

## 5. 에러 코드 및 응답

### 5.1 HTTP 상태 코드

| 코드 | 의미 | 사용 시나리오 |
|------|------|--------------|
| 200 | OK | 요청 성공 |
| 201 | Created | 리소스 생성 |
| 400 | Bad Request | 잘못된 요청 형식 |
| 401 | Unauthorized | 인증 실패 |
| 403 | Forbidden | 권한 없음 |
| 404 | Not Found | 리소스 없음 |
| 429 | Too Many Requests | Rate Limit 초과 |
| 500 | Internal Server Error | 서버 오류 |
| 502 | Bad Gateway | 업스트림 오류 |
| 503 | Service Unavailable | 서비스 불가 |

### 5.2 에러 응답 형식

```json
{
  "error": {
    "code": "rate_limit_exceeded",
    "message": "분당 요청 한도를 초과했습니다.",
    "type": "rate_limit_error",
    "param": null,
    "details": {
      "limit": 60,
      "remaining": 0,
      "reset_at": "2025-12-13T10:01:00Z"
    }
  },
  "request_id": "req_xxx"
}
```

### 5.3 에러 코드 목록

| 코드 | HTTP | 설명 |
|------|------|------|
| `invalid_request` | 400 | 요청 형식 오류 |
| `invalid_api_key` | 401 | API 키 유효하지 않음 |
| `insufficient_permissions` | 403 | 권한 부족 |
| `model_not_found` | 404 | 모델 없음 |
| `rate_limit_exceeded` | 429 | Rate Limit 초과 |
| `token_limit_exceeded` | 429 | 토큰 한도 초과 |
| `model_overloaded` | 503 | 모델 과부하 |
| `context_length_exceeded` | 400 | 컨텍스트 길이 초과 |
| `content_policy_violation` | 400 | 콘텐츠 정책 위반 |
| `pii_detected` | 400 | 개인정보 탐지 |
| `document_parse_failed` | 400 | 문서 파싱 실패 (Unstructured) |
| `embedding_failed` | 500 | 임베딩 생성 실패 |
| `reranking_failed` | 500 | 리랭킹 실패 |
| `graph_query_failed` | 500 | 그래프 쿼리 실패 (Neo4j) |

---

## 6. Rate Limiting 프로토콜

### 6.1 Rate Limit 헤더

```http
X-RateLimit-Limit-Requests: 60
X-RateLimit-Limit-Tokens: 100000
X-RateLimit-Remaining-Requests: 55
X-RateLimit-Remaining-Tokens: 95000
X-RateLimit-Reset-Requests: 2025-12-13T10:01:00Z
X-RateLimit-Reset-Tokens: 2025-12-13T10:01:00Z
Retry-After: 60
```

### 6.2 Rate Limit 정책

| 티어 | RPM | TPM | 동시 요청 | 임베딩 RPM | 리랭킹 RPM |
|------|-----|-----|----------|-----------|-----------|
| Free | 60 | 100K | 5 | 100 | 50 |
| Basic | 120 | 500K | 10 | 500 | 200 |
| Pro | 300 | 2M | 25 | 2000 | 1000 |
| Enterprise | 1000 | 10M | 100 | 10000 | 5000 |

### 6.3 429 응답 시 재시도 전략

```
Retry-Strategy:
  initial_delay: 1s
  max_delay: 60s
  multiplier: 2
  max_retries: 5
  jitter: true
```

---

## 7. 보안 프로토콜

### 7.1 JWT 토큰 구조

```json
{
  "header": {
    "alg": "RS256",
    "typ": "JWT",
    "kid": "key_xxx"
  },
  "payload": {
    "iss": "https://keycloak.company.com/realms/llmflow",
    "sub": "user_xxx",
    "aud": "llmflow-api",
    "exp": 1702000000,
    "iat": 1701996400,
    "tenant_id": "tenant_xxx",
    "department": "IT",
    "roles": ["user", "developer"],
    "permissions": ["chat:read", "chat:write", "documents:read", "graph:read"]
  }
}
```

### 7.2 API Key 형식

```
llmflow-sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

구조:
- prefix: llmflow-sk-
- random: 40자 영숫자
- 총 길이: 51자
```

### 7.3 요청 서명 (선택적)

```http
X-Signature-Timestamp: 1702000000
X-Signature: sha256=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

서명 생성:
signature = HMAC-SHA256(secret_key, timestamp + "." + request_body)
```

---

## 8. 모니터링/트레이싱 프로토콜

### 8.1 분산 트레이싱

**OpenTelemetry 헤더**:
```http
traceparent: 00-0af7651916cd43dd8448eb211c80319c-b7ad6b7169203331-01
tracestate: llmflow=tenant_xxx
```

### 8.2 메트릭 형식 (Prometheus)

```
# LLM 추론 메트릭
llmflow_inference_requests_total{model="llama-3.1-70b",status="success"} 1000
llmflow_inference_latency_seconds{model="llama-3.1-70b",quantile="0.99"} 2.5
llmflow_inference_tokens_total{model="llama-3.1-70b",type="input"} 500000
llmflow_inference_tokens_total{model="llama-3.1-70b",type="output"} 300000

# 임베딩 메트릭
llmflow_embedding_requests_total{model="bge-m3",status="success"} 5000
llmflow_embedding_latency_seconds{model="bge-m3",quantile="0.99"} 0.1

# 리랭킹 메트릭
llmflow_rerank_requests_total{model="bge-reranker-v2-m3",status="success"} 3000
llmflow_rerank_latency_seconds{model="bge-reranker-v2-m3",quantile="0.99"} 0.05

# 문서 파싱 메트릭
llmflow_parse_requests_total{parser="unstructured",status="success"} 500
llmflow_parse_latency_seconds{parser="unstructured",quantile="0.99"} 5.0

# GraphRAG 메트릭
llmflow_graph_queries_total{database="neo4j",status="success"} 2000
llmflow_graph_query_latency_seconds{database="neo4j",quantile="0.99"} 0.2

# GPU 메트릭
llmflow_gpu_utilization{node="gpu-node-1",gpu="0"} 0.85
llmflow_gpu_memory_used_bytes{node="gpu-node-1",gpu="0"} 68719476736

# 큐 메트릭
llmflow_queue_length{queue="inference"} 10
llmflow_queue_wait_seconds{queue="inference",quantile="0.99"} 0.5
```

### 8.3 로그 형식

```json
{
  "timestamp": "2025-12-13T10:00:00.000Z",
  "level": "INFO",
  "service": "dify-api",
  "trace_id": "trace_xxx",
  "span_id": "span_xxx",
  "tenant_id": "tenant_xxx",
  "user_id": "user_xxx",
  "message": "RAG search completed",
  "attributes": {
    "query": "연차 휴가 신청",
    "vector_results": 10,
    "graph_results": 5,
    "reranked_results": 5,
    "latency_ms": 112
  }
}
```

---

## 9. Webhook 프로토콜

### 9.1 Webhook 이벤트

| 이벤트 | 설명 |
|--------|------|
| `document.parsed` | 문서 파싱 완료 (Unstructured) |
| `document.indexed` | 문서 인덱싱 완료 |
| `graph.extracted` | 지식 그래프 추출 완료 |
| `workflow.completed` | 워크플로우 완료 |
| `model.deployed` | 모델 배포 완료 |
| `quota.exceeded` | 쿼터 초과 |
| `alert.triggered` | 알림 발생 |

### 9.2 Webhook 페이로드

```json
{
  "id": "webhook_xxx",
  "type": "document.indexed",
  "api_version": "2025-12-01",
  "created_at": "2025-12-13T10:00:00Z",
  "data": {
    "document_id": "doc_xxx",
    "dataset_id": "ds_xxx",
    "status": "completed",
    "chunks_count": 150,
    "entities_extracted": 45,
    "relations_extracted": 78
  },
  "tenant_id": "tenant_xxx"
}
```

### 9.3 Webhook 서명 검증

```python
import hmac
import hashlib

def verify_webhook(payload: bytes, signature: str, secret: str) -> bool:
    expected = hmac.new(
        secret.encode(),
        payload,
        hashlib.sha256
    ).hexdigest()
    return hmac.compare_digest(f"sha256={expected}", signature)
```

---

## 변경 이력

| 버전 | 날짜 | 변경 내용 | 작성자 |
|------|------|----------|--------|
| 1.0 | 2025-12-13 | 초기 작성 | LLMFlow Team |
| 2.0 | 2025-12-13 | 오픈소스 조합 가이드 v2.0 반영 - Ray 제거, TEI/Infinity API 추가, Unstructured API 추가, Neo4j Bolt 프로토콜 추가, GraphRAG 검색 API 추가 | LLMFlow Team |
